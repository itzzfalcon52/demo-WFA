{
  "best_global_step": 44486,
  "best_metric": 0.9947865609125747,
  "best_model_checkpoint": "/Users/hussain/Desktop/waf demo/backend/tiny_waf_model/checkpoint-44486",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 44486,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02247898215168817,
      "grad_norm": 0.13771003484725952,
      "learning_rate": 4.943914939531538e-05,
      "loss": 0.1968,
      "step": 500
    },
    {
      "epoch": 0.04495796430337634,
      "grad_norm": 0.05716557800769806,
      "learning_rate": 4.8877174841523177e-05,
      "loss": 0.035,
      "step": 1000
    },
    {
      "epoch": 0.06743694645506451,
      "grad_norm": 0.1331869214773178,
      "learning_rate": 4.8315200287730974e-05,
      "loss": 0.035,
      "step": 1500
    },
    {
      "epoch": 0.08991592860675268,
      "grad_norm": 0.026121802628040314,
      "learning_rate": 4.775322573393877e-05,
      "loss": 0.024,
      "step": 2000
    },
    {
      "epoch": 0.11239491075844085,
      "grad_norm": 0.022900601848959923,
      "learning_rate": 4.719125118014657e-05,
      "loss": 0.0257,
      "step": 2500
    },
    {
      "epoch": 0.13487389291012902,
      "grad_norm": 0.024661967530846596,
      "learning_rate": 4.662927662635436e-05,
      "loss": 0.0345,
      "step": 3000
    },
    {
      "epoch": 0.1573528750618172,
      "grad_norm": 0.019350875169038773,
      "learning_rate": 4.606730207256216e-05,
      "loss": 0.0244,
      "step": 3500
    },
    {
      "epoch": 0.17983185721350536,
      "grad_norm": 0.014407345093786716,
      "learning_rate": 4.550532751876995e-05,
      "loss": 0.0243,
      "step": 4000
    },
    {
      "epoch": 0.20231083936519353,
      "grad_norm": 0.06336240470409393,
      "learning_rate": 4.494335296497775e-05,
      "loss": 0.0215,
      "step": 4500
    },
    {
      "epoch": 0.2247898215168817,
      "grad_norm": 0.01225656270980835,
      "learning_rate": 4.4381378411185546e-05,
      "loss": 0.0219,
      "step": 5000
    },
    {
      "epoch": 0.24726880366856988,
      "grad_norm": 0.019369084388017654,
      "learning_rate": 4.381940385739334e-05,
      "loss": 0.0283,
      "step": 5500
    },
    {
      "epoch": 0.26974778582025805,
      "grad_norm": 0.010875532403588295,
      "learning_rate": 4.3257429303601135e-05,
      "loss": 0.0203,
      "step": 6000
    },
    {
      "epoch": 0.29222676797194624,
      "grad_norm": 7.413219451904297,
      "learning_rate": 4.269545474980893e-05,
      "loss": 0.0244,
      "step": 6500
    },
    {
      "epoch": 0.3147057501236344,
      "grad_norm": 0.028926895931363106,
      "learning_rate": 4.213348019601673e-05,
      "loss": 0.024,
      "step": 7000
    },
    {
      "epoch": 0.3371847322753226,
      "grad_norm": 0.0056219701655209064,
      "learning_rate": 4.157150564222452e-05,
      "loss": 0.0145,
      "step": 7500
    },
    {
      "epoch": 0.35966371442701073,
      "grad_norm": 0.014743809588253498,
      "learning_rate": 4.100953108843232e-05,
      "loss": 0.0263,
      "step": 8000
    },
    {
      "epoch": 0.3821426965786989,
      "grad_norm": 0.023341448977589607,
      "learning_rate": 4.044755653464011e-05,
      "loss": 0.0255,
      "step": 8500
    },
    {
      "epoch": 0.40462167873038707,
      "grad_norm": 3.130248546600342,
      "learning_rate": 3.988558198084791e-05,
      "loss": 0.0236,
      "step": 9000
    },
    {
      "epoch": 0.42710066088207527,
      "grad_norm": 0.009914319030940533,
      "learning_rate": 3.9323607427055706e-05,
      "loss": 0.0191,
      "step": 9500
    },
    {
      "epoch": 0.4495796430337634,
      "grad_norm": 0.0255941953510046,
      "learning_rate": 3.87616328732635e-05,
      "loss": 0.0248,
      "step": 10000
    },
    {
      "epoch": 0.4720586251854516,
      "grad_norm": 0.004206653218716383,
      "learning_rate": 3.81996583194713e-05,
      "loss": 0.0238,
      "step": 10500
    },
    {
      "epoch": 0.49453760733713975,
      "grad_norm": 0.009756115265190601,
      "learning_rate": 3.763768376567909e-05,
      "loss": 0.0214,
      "step": 11000
    },
    {
      "epoch": 0.5170165894888279,
      "grad_norm": 0.006101308390498161,
      "learning_rate": 3.707570921188689e-05,
      "loss": 0.0268,
      "step": 11500
    },
    {
      "epoch": 0.5394955716405161,
      "grad_norm": 0.022967875003814697,
      "learning_rate": 3.651373465809468e-05,
      "loss": 0.0181,
      "step": 12000
    },
    {
      "epoch": 0.5619745537922043,
      "grad_norm": 10.059672355651855,
      "learning_rate": 3.595176010430248e-05,
      "loss": 0.0137,
      "step": 12500
    },
    {
      "epoch": 0.5844535359438925,
      "grad_norm": 0.006968396250158548,
      "learning_rate": 3.538978555051028e-05,
      "loss": 0.0155,
      "step": 13000
    },
    {
      "epoch": 0.6069325180955807,
      "grad_norm": 0.003619183786213398,
      "learning_rate": 3.482781099671807e-05,
      "loss": 0.0223,
      "step": 13500
    },
    {
      "epoch": 0.6294115002472688,
      "grad_norm": 6.285579681396484,
      "learning_rate": 3.4265836442925866e-05,
      "loss": 0.0178,
      "step": 14000
    },
    {
      "epoch": 0.651890482398957,
      "grad_norm": 0.02953377366065979,
      "learning_rate": 3.3703861889133664e-05,
      "loss": 0.016,
      "step": 14500
    },
    {
      "epoch": 0.6743694645506452,
      "grad_norm": 0.0012556136352941394,
      "learning_rate": 3.314188733534146e-05,
      "loss": 0.019,
      "step": 15000
    },
    {
      "epoch": 0.6968484467023334,
      "grad_norm": 0.00206274027004838,
      "learning_rate": 3.257991278154925e-05,
      "loss": 0.0236,
      "step": 15500
    },
    {
      "epoch": 0.7193274288540215,
      "grad_norm": 0.009923532605171204,
      "learning_rate": 3.201793822775705e-05,
      "loss": 0.0177,
      "step": 16000
    },
    {
      "epoch": 0.7418064110057097,
      "grad_norm": 0.0021976465359330177,
      "learning_rate": 3.145596367396484e-05,
      "loss": 0.0135,
      "step": 16500
    },
    {
      "epoch": 0.7642853931573979,
      "grad_norm": 0.024424990639090538,
      "learning_rate": 3.089398912017264e-05,
      "loss": 0.0206,
      "step": 17000
    },
    {
      "epoch": 0.786764375309086,
      "grad_norm": 0.0025568166747689247,
      "learning_rate": 3.0332014566380434e-05,
      "loss": 0.0202,
      "step": 17500
    },
    {
      "epoch": 0.8092433574607741,
      "grad_norm": 0.02582324482500553,
      "learning_rate": 2.9770040012588228e-05,
      "loss": 0.0224,
      "step": 18000
    },
    {
      "epoch": 0.8317223396124623,
      "grad_norm": 0.0024651980493217707,
      "learning_rate": 2.9208065458796026e-05,
      "loss": 0.0137,
      "step": 18500
    },
    {
      "epoch": 0.8542013217641505,
      "grad_norm": 0.0020768893882632256,
      "learning_rate": 2.8646090905003824e-05,
      "loss": 0.0138,
      "step": 19000
    },
    {
      "epoch": 0.8766803039158387,
      "grad_norm": 0.02939414419233799,
      "learning_rate": 2.8084116351211622e-05,
      "loss": 0.0108,
      "step": 19500
    },
    {
      "epoch": 0.8991592860675268,
      "grad_norm": 0.05249232053756714,
      "learning_rate": 2.7522141797419416e-05,
      "loss": 0.0134,
      "step": 20000
    },
    {
      "epoch": 0.921638268219215,
      "grad_norm": 0.26382121443748474,
      "learning_rate": 2.696016724362721e-05,
      "loss": 0.0209,
      "step": 20500
    },
    {
      "epoch": 0.9441172503709032,
      "grad_norm": 0.004668658133596182,
      "learning_rate": 2.6398192689835005e-05,
      "loss": 0.0161,
      "step": 21000
    },
    {
      "epoch": 0.9665962325225914,
      "grad_norm": 0.018049363046884537,
      "learning_rate": 2.58362181360428e-05,
      "loss": 0.0136,
      "step": 21500
    },
    {
      "epoch": 0.9890752146742795,
      "grad_norm": 0.0066394442692399025,
      "learning_rate": 2.5274243582250594e-05,
      "loss": 0.0112,
      "step": 22000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9974440284656747,
      "eval_f1": 0.9946407525184016,
      "eval_fn": 159,
      "eval_fp": 82,
      "eval_loss": 0.021718978881835938,
      "eval_pr_auc": 0.9991401353051772,
      "eval_precision": 0.9963467878463869,
      "eval_recall": 0.9929405496603472,
      "eval_roc_auc": 0.9995451465963242,
      "eval_runtime": 111.2018,
      "eval_samples_per_second": 847.909,
      "eval_steps_per_second": 53.003,
      "eval_tn": 71684,
      "eval_tp": 22364,
      "step": 22243
    },
    {
      "epoch": 1.0115541968259678,
      "grad_norm": 0.0038377519231289625,
      "learning_rate": 2.4712269028458392e-05,
      "loss": 0.0128,
      "step": 22500
    },
    {
      "epoch": 1.0340331789776558,
      "grad_norm": 0.0008615643018856645,
      "learning_rate": 2.415029447466619e-05,
      "loss": 0.0139,
      "step": 23000
    },
    {
      "epoch": 1.056512161129344,
      "grad_norm": 0.003303458448499441,
      "learning_rate": 2.3588319920873984e-05,
      "loss": 0.0087,
      "step": 23500
    },
    {
      "epoch": 1.0789911432810322,
      "grad_norm": 0.012780279852449894,
      "learning_rate": 2.3026345367081782e-05,
      "loss": 0.0166,
      "step": 24000
    },
    {
      "epoch": 1.1014701254327204,
      "grad_norm": 0.0034500339534133673,
      "learning_rate": 2.2464370813289576e-05,
      "loss": 0.0107,
      "step": 24500
    },
    {
      "epoch": 1.1239491075844086,
      "grad_norm": 0.009590384550392628,
      "learning_rate": 2.190239625949737e-05,
      "loss": 0.0137,
      "step": 25000
    },
    {
      "epoch": 1.1464280897360968,
      "grad_norm": 0.026534197852015495,
      "learning_rate": 2.1340421705705165e-05,
      "loss": 0.0179,
      "step": 25500
    },
    {
      "epoch": 1.168907071887785,
      "grad_norm": 0.0013434977736324072,
      "learning_rate": 2.0778447151912963e-05,
      "loss": 0.0084,
      "step": 26000
    },
    {
      "epoch": 1.1913860540394732,
      "grad_norm": 0.007510851603001356,
      "learning_rate": 2.0216472598120757e-05,
      "loss": 0.0169,
      "step": 26500
    },
    {
      "epoch": 1.2138650361911614,
      "grad_norm": 0.012313331477344036,
      "learning_rate": 1.9654498044328555e-05,
      "loss": 0.0092,
      "step": 27000
    },
    {
      "epoch": 1.2363440183428493,
      "grad_norm": 0.01209620013833046,
      "learning_rate": 1.909252349053635e-05,
      "loss": 0.018,
      "step": 27500
    },
    {
      "epoch": 1.2588230004945375,
      "grad_norm": 0.0011619505239650607,
      "learning_rate": 1.8530548936744148e-05,
      "loss": 0.0088,
      "step": 28000
    },
    {
      "epoch": 1.2813019826462257,
      "grad_norm": 0.013343201018869877,
      "learning_rate": 1.7968574382951942e-05,
      "loss": 0.014,
      "step": 28500
    },
    {
      "epoch": 1.303780964797914,
      "grad_norm": 0.002671957015991211,
      "learning_rate": 1.7406599829159736e-05,
      "loss": 0.0118,
      "step": 29000
    },
    {
      "epoch": 1.3262599469496021,
      "grad_norm": 0.0014953386271372437,
      "learning_rate": 1.684462527536753e-05,
      "loss": 0.0101,
      "step": 29500
    },
    {
      "epoch": 1.3487389291012903,
      "grad_norm": 0.0016033031279221177,
      "learning_rate": 1.6282650721575325e-05,
      "loss": 0.0152,
      "step": 30000
    },
    {
      "epoch": 1.3712179112529785,
      "grad_norm": 0.0017645277548581362,
      "learning_rate": 1.5720676167783123e-05,
      "loss": 0.0097,
      "step": 30500
    },
    {
      "epoch": 1.3936968934046665,
      "grad_norm": 0.0005479336250573397,
      "learning_rate": 1.515870161399092e-05,
      "loss": 0.007,
      "step": 31000
    },
    {
      "epoch": 1.416175875556355,
      "grad_norm": 0.00043543081847019494,
      "learning_rate": 1.4596727060198714e-05,
      "loss": 0.0053,
      "step": 31500
    },
    {
      "epoch": 1.438654857708043,
      "grad_norm": 0.0033304670359939337,
      "learning_rate": 1.403475250640651e-05,
      "loss": 0.0104,
      "step": 32000
    },
    {
      "epoch": 1.461133839859731,
      "grad_norm": 0.0007479034247808158,
      "learning_rate": 1.3472777952614308e-05,
      "loss": 0.0141,
      "step": 32500
    },
    {
      "epoch": 1.4836128220114193,
      "grad_norm": 0.0005452525219880044,
      "learning_rate": 1.2910803398822102e-05,
      "loss": 0.0085,
      "step": 33000
    },
    {
      "epoch": 1.5060918041631075,
      "grad_norm": 0.008756288327276707,
      "learning_rate": 1.2348828845029897e-05,
      "loss": 0.007,
      "step": 33500
    },
    {
      "epoch": 1.5285707863147957,
      "grad_norm": 0.04377423971891403,
      "learning_rate": 1.1786854291237694e-05,
      "loss": 0.0053,
      "step": 34000
    },
    {
      "epoch": 1.5510497684664837,
      "grad_norm": 0.0026857536286115646,
      "learning_rate": 1.1224879737445489e-05,
      "loss": 0.0153,
      "step": 34500
    },
    {
      "epoch": 1.573528750618172,
      "grad_norm": 0.0030858099926263094,
      "learning_rate": 1.0662905183653285e-05,
      "loss": 0.0089,
      "step": 35000
    },
    {
      "epoch": 1.59600773276986,
      "grad_norm": 0.002463952172547579,
      "learning_rate": 1.010093062986108e-05,
      "loss": 0.0108,
      "step": 35500
    },
    {
      "epoch": 1.6184867149215485,
      "grad_norm": 0.0055865077301859856,
      "learning_rate": 9.538956076068877e-06,
      "loss": 0.0138,
      "step": 36000
    },
    {
      "epoch": 1.6409656970732365,
      "grad_norm": 0.0005618169670924544,
      "learning_rate": 8.976981522276672e-06,
      "loss": 0.0115,
      "step": 36500
    },
    {
      "epoch": 1.6634446792249247,
      "grad_norm": 0.0032825395464897156,
      "learning_rate": 8.415006968484468e-06,
      "loss": 0.0116,
      "step": 37000
    },
    {
      "epoch": 1.6859236613766129,
      "grad_norm": 0.0045369816944003105,
      "learning_rate": 7.853032414692262e-06,
      "loss": 0.0151,
      "step": 37500
    },
    {
      "epoch": 1.708402643528301,
      "grad_norm": 0.01639614813029766,
      "learning_rate": 7.291057860900059e-06,
      "loss": 0.0139,
      "step": 38000
    },
    {
      "epoch": 1.7308816256799893,
      "grad_norm": 0.005347225349396467,
      "learning_rate": 6.729083307107855e-06,
      "loss": 0.0162,
      "step": 38500
    },
    {
      "epoch": 1.7533606078316772,
      "grad_norm": 0.004031033255159855,
      "learning_rate": 6.16710875331565e-06,
      "loss": 0.0072,
      "step": 39000
    },
    {
      "epoch": 1.7758395899833657,
      "grad_norm": 0.01936998777091503,
      "learning_rate": 5.605134199523446e-06,
      "loss": 0.008,
      "step": 39500
    },
    {
      "epoch": 1.7983185721350536,
      "grad_norm": 0.0014281700132414699,
      "learning_rate": 5.043159645731241e-06,
      "loss": 0.013,
      "step": 40000
    },
    {
      "epoch": 1.820797554286742,
      "grad_norm": 0.012649400159716606,
      "learning_rate": 4.4811850919390374e-06,
      "loss": 0.0148,
      "step": 40500
    },
    {
      "epoch": 1.84327653643843,
      "grad_norm": 0.001648257253691554,
      "learning_rate": 3.919210538146833e-06,
      "loss": 0.0112,
      "step": 41000
    },
    {
      "epoch": 1.8657555185901182,
      "grad_norm": 0.020287973806262016,
      "learning_rate": 3.3572359843546285e-06,
      "loss": 0.0107,
      "step": 41500
    },
    {
      "epoch": 1.8882345007418064,
      "grad_norm": 0.0043257856741547585,
      "learning_rate": 2.795261430562424e-06,
      "loss": 0.0089,
      "step": 42000
    },
    {
      "epoch": 1.9107134828934946,
      "grad_norm": 0.0013378806179389358,
      "learning_rate": 2.23328687677022e-06,
      "loss": 0.0056,
      "step": 42500
    },
    {
      "epoch": 1.9331924650451828,
      "grad_norm": 0.0006448110216297209,
      "learning_rate": 1.6713123229780158e-06,
      "loss": 0.0092,
      "step": 43000
    },
    {
      "epoch": 1.9556714471968708,
      "grad_norm": 0.0010979080107063055,
      "learning_rate": 1.1093377691858113e-06,
      "loss": 0.0084,
      "step": 43500
    },
    {
      "epoch": 1.9781504293485592,
      "grad_norm": 0.0006301151006482542,
      "learning_rate": 5.47363215393607e-07,
      "loss": 0.0165,
      "step": 44000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9975182683027712,
      "eval_f1": 0.9947865609125747,
      "eval_fn": 198,
      "eval_fp": 36,
      "eval_loss": 0.024351604282855988,
      "eval_pr_auc": 0.9991552159902257,
      "eval_precision": 0.9983900541120702,
      "eval_recall": 0.991208986369489,
      "eval_roc_auc": 0.9995722790451109,
      "eval_runtime": 112.4033,
      "eval_samples_per_second": 838.845,
      "eval_steps_per_second": 52.436,
      "eval_tn": 71730,
      "eval_tp": 22325,
      "step": 44486
    }
  ],
  "logging_steps": 500,
  "max_steps": 44486,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 113037455301120.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
